# KR Sentiment Agent

í•œêµ­ì–´ **ABSA(Aspect-Based Sentiment Analysis)** íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.  
ëˆ„êµ¬ë‚˜ ë”°ë¼ í•  ìˆ˜ ìˆë„ë¡, ì‹¤í–‰ ìˆœì„œì™€ ê²°ê³¼ í™•ì¸ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.  
ê¸°ë³¸ íë¦„ì€ Stage1(ATE/ATSA/Validator) â†’ **í† ë¡ (Debate)** â†’ Stage2 ë¦¬ë·° â†’ Moderator ê·œì¹™ ê²°ì •ì…ë‹ˆë‹¤.

## ğŸ‘€ ì´ í”„ë¡œì íŠ¸ê°€ í•˜ëŠ” ì¼ (í•œëˆˆì— ë³´ê¸°)

1) **ë¬¸ì¥ì—ì„œ "ë¬´ì—‡(Aspect)"ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤**  
   ì˜ˆ: "ì„œë¹„ìŠ¤ëŠ” ì¹œì ˆí–ˆì§€ë§Œ ìŒì‹ì€ ë³„ë¡œì˜€ì–´" â†’ Aspect = ì„œë¹„ìŠ¤, ìŒì‹  
2) **ê° Aspectì˜ ê°ì •ì„ íŒë‹¨í•©ë‹ˆë‹¤**  
   ì˜ˆ: ì„œë¹„ìŠ¤=ê¸ì •, ìŒì‹=ë¶€ì •  
3) **ì—ì´ì „íŠ¸ë“¤ì´ í† ë¡ í•©ë‹ˆë‹¤**  
   ë¶„ì„ê°€/ê³µê°ê°€/ë¹„í‰ê°€ê°€ ì„œë¡œ ë°˜ë°•Â·í•©ì˜í•˜ê³ , ì‹¬íŒì´ ìš”ì•½í•©ë‹ˆë‹¤.  
4) **í† ë¡  ë‚´ìš©ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ë¦¬ë·°í•©ë‹ˆë‹¤**  
   Stage2ì—ì„œ ë³´ì •/ê²€ì¦í•˜ê³ , Moderatorê°€ ìµœì¢… ê²°ë¡ ì„ ëƒ…ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

- ğŸ­ **í† ë¡  ë ˆì´ì–´**: ë¶„ì„ê°€/ê³µê°ê°€/ë¹„í‰ê°€ í† ë¡  + ì‹¬íŒ ìš”ì•½
- ğŸ” **Stage1 â†’ Debate â†’ Stage2 ë¦¬ë·°** êµ¬ì¡°
- ğŸ§­ **Moderator ê·œì¹™**: Rule Aâ€“D + Rule E(í† ë¡  í•©ì˜ íŒíŠ¸)
- ğŸ“Š **í† ë¡  ë§¤í•‘ í’ˆì§ˆ ì§€í‘œ**: mapping coverage/ì‹¤íŒ¨ ì›ì¸ ì§‘ê³„
- ğŸ§ª **Ablation ì§€ì›**: debate override on/off ë¹„êµ
- ğŸ“ **Tuple í‰ê°€**: gold_tuples ê¸°ë°˜ (aspect_ref, aspect_term, polarity) F1; `docs/absa_tuple_eval.md` ì°¸ê³ 

## ğŸš€ ì„¤ì¹˜ (ì²˜ìŒ 1íšŒ)

```bash
git clone https://github.com/cloudnative-app/kr-sentimental-agent.git
cd kr-sentimental-agent
pip install -r requirements.txt
```

## ğŸ”‘ í™˜ê²½ ì„¤ì • (ì²˜ìŒ 1íšŒ)

### 1) Backbone ì„¤ì •

ê¸°ë³¸ê°’ì€ **mock(ê°€ì§œ ëª¨ë¸)** ì…ë‹ˆë‹¤.  
ì‹¤ì œ LLMì„ ì“°ë ¤ë©´ ì•„ë˜ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.

```bash
# ì˜ˆ: OpenAI
BACKBONE_PROVIDER=openai
BACKBONE_MODEL=gpt-4o-mini
OPENAI_API_KEY=your_openai_api_key
```

ë‹¤ë¥¸ Providerë¥¼ ì“°ê³  ì‹¶ë‹¤ë©´:
```bash
# Anthropic
BACKBONE_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_anthropic_api_key

# Google Gemini
BACKBONE_PROVIDER=google
GOOGLE_API_KEY=your_google_api_key
GENAI_API_KEY=your_genai_api_key
```

## âœ… ê°€ì¥ ì‰¬ìš´ ì‹¤í–‰ ë°©ë²• (ê¶Œì¥)

```bash
# ë‹¨ì¼ ì‹¤í–‰ (smoke)
python scripts/run_pipeline.py --config experiments/configs/experiment_mini.yaml --run-id experiment_mini --mode proposed --profile smoke --with_metrics

# ì‹œë“œ ë°˜ë³µ + ë¨¸ì§• (paper, mini2/mini3 ë“±)
python scripts/run_pipeline.py --config experiments/configs/experiment_mini2.yaml --run-id experiment_mini2 --mode proposed --profile paper --with_metrics --metrics_profile paper_main --with_aggregate
```

ì‹¤í–‰ í›„ í™•ì¸í•  ê²ƒ:
- ê²°ê³¼ ë””ë ‰í„°ë¦¬: `results/experiment_mini_proposed/` (ë‹¨ì¼ ì‹¤í–‰) ë˜ëŠ” ì‹œë“œ ë°˜ë³µ ì‹œ `results/experiment_mini__seed42_proposed/` ë“±
- ê²°ê³¼ íŒŒì¼: `results/experiment_mini_proposed/outputs.jsonl`, `scorecards.jsonl`
- ë¦¬í¬íŠ¸ HTML: `reports/experiment_mini_proposed/metric_report.html`
- ì‹œë“œ ë¨¸ì§• í›„: `results/experiment_mini_aggregated/`, ë¨¸ì§€ ë¦¬í¬íŠ¸ `reports/merged_run_experiment_mini/metric_report.html`

## ğŸ§ª ì‹¤í—˜ ì‹¤í–‰ (ì¡°ê¸ˆ ë” ìì„¸íˆ)

### 1) ê¸°ë³¸ ì‹¤í—˜ ì‹¤í–‰ (run_experiments)

```bash
python experiments/scripts/run_experiments.py \
    --config experiments/configs/default.yaml \
    --mode proposed \  # optional override; defaults to config run_mode or env RUN_MODE
    --run-id demo_run
```

### 2) ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (test_small.csv)

```bash
python experiments/scripts/run_experiments.py \
    --config experiments/configs/test_small.yaml \
    --run-id test_small \
    --mode proposed
```

### 3) í† ë¡  ì˜¨/ì˜¤í”„ Â· Debate override ë¹„êµ

**í•œ ëŸ°ì—ì„œ í† ë¡  ì˜¨/ì˜¤í”„ë¥¼ ë™ì‹œì— ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.** í•œ ë²ˆ ì‹¤í–‰ ì‹œ config í•˜ë‚˜ë§Œ ì ìš©ë˜ë¯€ë¡œ, í† ë¡  ì¼œê¸°/ë„ê¸° ë¹„êµë¥¼ í•˜ë ¤ë©´ **ì„œë¡œ ë‹¤ë¥¸ configë¡œ ë‘ ë²ˆ ë”°ë¡œ ì‹¤í–‰**í•œ ë’¤ ê²°ê³¼ë¥¼ ë¹„êµí•´ì•¼ í•©ë‹ˆë‹¤.

| ë¹„êµ ëª©ì  | ì‹œí–‰ ë°©ë²• |
|-----------|-----------|
| **í† ë¡  ë‹¨ê³„ ìì²´ ì˜¨ vs ì˜¤í”„** | (1) í† ë¡  ON: `experiment_mini2.yaml` ë“± `enable_debate: true` configë¡œ ì‹¤í–‰ â†’ (2) í† ë¡  OFF: `experiments/configs/abl_no_debate.yaml` ë¡œ **ê°™ì€ ë°ì´í„°Â·ì‹œë“œ**ë¡œ í•œ ë²ˆ ë” ì‹¤í–‰. run_idë¥¼ êµ¬ë¶„í•´ ë‘ë©´ ë¨(ì˜ˆ: `experiment_mini2` vs `abl_no_debate`). |
| **Debate override ON vs OFF** (í† ë¡ ì€ ë‘˜ ë‹¤ ì¼œê³ , Moderatorê°€ í† ë¡  íŒíŠ¸ë§Œ ì“°ëŠ”ì§€ ì—¬ë¶€) | `scripts/run_debate_override_ablation.py` í•œ ë²ˆ ì‹¤í–‰. ë‚´ë¶€ì—ì„œ override ON configì™€ `abl_no_debate_override.yaml`(override OFF)ì„ ê°ê° ì‹¤í–‰ í›„ ë©”íŠ¸ë¦­Â·ë¦¬í¬íŠ¸ ìƒì„±. |

**í† ë¡  ì™„ì „ ì˜¤í”„ ì˜ˆì‹œ (mini2 ë°ì´í„°):**
```bash
# í† ë¡  ON (ê¸°ë³¸)
python scripts/run_pipeline.py --config experiments/configs/experiment_mini2.yaml --run-id experiment_mini2 --mode proposed --profile paper --with_metrics --metrics_profile paper_main

# í† ë¡  OFF (ablation)
python scripts/run_pipeline.py --config experiments/configs/abl_no_debate.yaml --run-id abl_no_debate --mode proposed --profile paper --with_metrics --metrics_profile paper_main
```
ì´í›„ `results/experiment_mini2_proposed/` vs `results/abl_no_debate_proposed/` (ë˜ëŠ” ì‹œë“œ ë°˜ë³µ ì‹œ ê°ê° `*__seed42_proposed` ë“±)ì˜ derived/metricsÂ·ë¦¬í¬íŠ¸ë¥¼ ë¹„êµí•˜ë©´ ë©ë‹ˆë‹¤.

**Overrideë§Œ ë¹„êµ (í† ë¡ ì€ ë‘˜ ë‹¤ ON):**
```bash
python scripts/run_debate_override_ablation.py --run-id debate_override_ablation --profile smoke
```
- ê²°ê³¼: `results/debate_override_ablation_override_on_proposed/`, `results/debate_override_ablation_override_off_proposed/`

## ğŸ“‚ ê²°ê³¼Â·ê²½ë¡œ ê·œì¹™

- **ë‹¨ì¼ ì‹¤í–‰**: `results/<run_id>_<mode>/`, `reports/<run_id>_<mode>/`
- **ì‹œë“œ ë°˜ë³µ**: `results/<run_id>__seed<N>_<mode>/` (ë®ì–´ì“°ê¸° ì—†ìŒ)
- **ë¨¸ì§• í›„**: `results/<run_id>_aggregated/` (merged_scorecards.jsonl, merged_metrics/), ë¨¸ì§€ ë¦¬í¬íŠ¸ëŠ” `reports/merged_run_<run_id>/metric_report.html`
- **Scorecard ë®ì–´ì“°ê¸° ê¸ˆì§€**: `results/<run_id>/scorecards.jsonl`ì€ **ì›ë³¸(run_experiments)** ì „ìš©. smoke ì¬ìƒì„± ì‹œ ë°˜ë“œì‹œ `--out results/<run_id>/derived/scorecards/scorecards.smoke.jsonl` (ë˜ëŠ” `scorecards.smoke.gold.jsonl`) ì‚¬ìš©. ìƒì„¸: `docs/scorecard_path_and_consistency_checklist.md`

## ğŸ“‚ ê²°ê³¼ë¥¼ ì½ëŠ” ë°©ë²•

### 1) `outputs.jsonl`
ê° ë¬¸ì¥ì— ëŒ€í•´ **ìµœì¢… ê°ì • ê²°ê³¼**ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.  
`debate` í•­ëª©ì—ëŠ” í† ë¡  ìš”ì•½ì´ í¬í•¨ë©ë‹ˆë‹¤.

### 2) `scorecards.jsonl`
ê° ìƒ˜í”Œì˜ **ìƒì„¸ ì ìˆ˜/ë§¤í•‘ í’ˆì§ˆ**ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.  
`debate.mapping_coverage`ê°€ ë†’ì„ìˆ˜ë¡ í† ë¡ -ë¦¬ë·° ì—°ê²°ì´ ì˜ ëœ ê²ƒì…ë‹ˆë‹¤.

### 3) `metric_report.html`
ë¸Œë¼ìš°ì €ë¡œ ì—´ì–´ **ì „ì²´ ì§€í‘œì™€ ê²½ê³ **ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  
KPI ì¹´ë“œì— ê²½ê³ (LOW/HIGH)ê°€ ëœ¨ë©´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.

## ğŸ§­ ìš©ì–´ ê°„ë‹¨ ì„¤ëª…

- **ABSA**: Aspect(ëŒ€ìƒ)ë³„ ê°ì„± ë¶„ì„  
- **ATE**: Aspect Extraction (ëŒ€ìƒì„ ì°¾ëŠ” ë‹¨ê³„)  
- **ATSA**: Aspect-Target Sentiment Analysis (ëŒ€ìƒë³„ ê°ì • íŒë‹¨)  
- **Validator**: êµ¬ì¡° ê²€ì¦  
- **Debate**: ì—ì´ì „íŠ¸ í† ë¡ /í•©ì˜ ë‹¨ê³„  
- **Stage2 ë¦¬ë·°**: í† ë¡  ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ì¬ê²€í†   
- **Moderator**: ìµœì¢… ê·œì¹™ ê²°ì •

## ğŸ”§ ì‹¤í—˜ ì¡°ê±´Â·ë°ì´í„°

### í† ë¡  ë° Stage2 ë¦¬ë·°
ìì„¸í•œ êµ¬ì¡°ëŠ” `docs/pipeline_structure_and_rules.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### ì†Œê·œëª¨ ë°ì´í„°ì…‹ (mini / mini2 / mini3)
- **mini**: `scripts/make_mini_dataset.py` â†’ `experiments/configs/datasets/mini/` (train/valid, gold_tuples)
- **mini2**: `scripts/make_mini2_dataset.py` â†’ `experiments/configs/datasets/mini2/` (ì‹œë“œ 2ê°œìš©)
- **mini3**: `scripts/make_mini3_dataset.py` â†’ `experiments/configs/datasets/mini3/` (train 570, valid 30)
- ê³¨ë“œ í¬ë§·: `gold_tuples` (aspect_ref, aspect_term, polarity). ì •ì˜: `docs/absa_tuple_eval.md`

## ğŸ­ ì—ì´ì „íŠ¸Â·ìŠ¤í‚¤ë§ˆÂ·í”„ë¡¬í”„íŠ¸ (í˜„ì¬ íŒŒì´í”„ë¼ì¸)

íŒŒì´í”„ë¼ì¸ì€ **Stage1 â†’ (ì„ íƒ) Debate â†’ Stage2 ë¦¬ë·° â†’ Moderator** ìˆœì„œë¡œ ë™ì‘í•©ë‹ˆë‹¤.

**í˜ë¥´ì†Œë‚˜ ë¶€ì—¬**: **í† ë¡  ë‹¨ê³„(Debate)ì—ì„œë§Œ** í˜ë¥´ì†Œë‚˜ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤. ë°œì–¸ì 3ëª…(ë¶„ì„ê°€/ê³µê°ê°€/ë¹„í‰ê°€ íŒ¨ë„)ì—ê²Œë§Œ `DebatePersona`ê°€ ì£¼ì…ë˜ë©°, Stage1/Stage2ì˜ **ATEÂ·ATSAÂ·Validatorì—ëŠ” í˜ë¥´ì†Œë‚˜ê°€ ì—†ê³ ** ê°ê° ê³ ì •ëœ ì—­í• (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸)ë§Œ ê°€ì§‘ë‹ˆë‹¤.

**API í˜¸ì¶œ íšŸìˆ˜** (ìƒ˜í”Œë‹¹, `enable_stage2=true`, `enable_debate=true`, ê¸°ë³¸ ì„¤ì •):  
Stage1(ATEÂ·ATSAÂ·Validator ê° 1íšŒ) **3** + Debate(ë¼ìš´ë“œ 2Ã— ë°œì–¸ì 3ëª… **6** + Judge **1**) **7** + Stage2(ATEÂ·ATSAÂ·Validator ê° 1íšŒ) **3** = **ì´ 13íšŒ**. ModeratorëŠ” LLM ë¯¸ì‚¬ìš©(ê·œì¹™ ê¸°ë°˜).

**í† ë¡  ë°œì–¸ì vs Stage ì—ì´ì „íŠ¸**: í† ë¡ ì— ì°¸ê°€í•˜ëŠ” ë°œì–¸ì(ë¶„ì„ê°€/ê³µê°ê°€/ë¹„í‰ê°€ íŒ¨ë„)ëŠ” **ATEÂ·ATSAÂ·Validatorì™€ ë‹¤ë¥¸ ë…ë¦½ì ì¸ ì—ì´ì „íŠ¸**ì…ë‹ˆë‹¤. Stage1/Stage2ëŠ” `ATEAgent`, `ATSAAgent`, `ValidatorAgent`ê°€ ê°ê° `ate_stage1/2`, `atsa_stage1/2`, `validator_stage1/2` í”„ë¡¬í”„íŠ¸ì™€ êµ¬ì¡°í™” ìŠ¤í‚¤ë§ˆë¡œ í˜¸ì¶œë˜ê³ , í† ë¡ ì€ `DebateOrchestrator`ê°€ **ë™ì¼ ë°±ë³¸(LLM)**ì— **debate_speaker** í”„ë¡¬í”„íŠ¸ + ë°œì–¸ìë³„ í˜ë¥´ì†Œë‚˜(JSON)ë¥¼ ë„£ì–´ í˜¸ì¶œí•˜ë©°, ì¶œë ¥ ìŠ¤í‚¤ë§ˆëŠ” `DebateTurn`(planning/reflection/message)ì…ë‹ˆë‹¤. ì¦‰, í† ë¡  3ì¸ì€ ë³„ë„ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ê°€ ì•„ë‹ˆë¼ â€œdebate_speaker 1íšŒ í˜¸ì¶œ Ã— í˜ë¥´ì†Œë‚˜ë§Œ ë°”ê¿”ê°€ë©° 3ëª…ë¶„â€ì…ë‹ˆë‹¤.

### ABSA íŒŒì´í”„ë¼ì¸ ì—ì´ì „íŠ¸ (Stage1/Stage2, í˜ë¥´ì†Œë‚˜ ì—†ìŒ)

| ì—ì´ì „íŠ¸ | ì—­í•  | í”„ë¡¬í”„íŠ¸ | ìŠ¤í‚¤ë§ˆ (schemas/agent_outputs.py) |
|----------|------|----------|-----------------------------------|
| **ATE** (Aspect Extraction) | ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ **ëª…ì‹œì  ì†ì„±(Explicit Aspect Terms)** ì¶”ì¶œ. ëª…ì‚¬/ëª…ì‚¬êµ¬ ë‹¨ìœ„ span, ì§€ë°°ì†Œ(ì„œìˆ ì–´) íŒŒì•…. | `agents/prompts/ate_stage1.md`, `ate_stage2.md` | `AspectExtractionStage1Schema` (aspects: term, span, normalized, syntactic_head, confidence, rationale), Stage2: `AspectExtractionReviewItem` |
| **ATSA** (Aspect Sentiment) | ê° ì†ì„±ë³„ **ê°ì„± ê·¹ì„±(positive/negative/neutral)** ê²°ì •. Opinion TermÂ·ë¶€ì •/ëŒ€ì¡°/ì¡°ê±´ ë°˜ì „Â·í™•ë¥  ë¶„í¬. | `agents/prompts/atsa_stage1.md`, `atsa_stage2.md` | `AspectSentimentStage1Schema` (aspect_sentiments: aspect_ref, polarity, opinion_term, evidence, confidence), Stage2: `SentimentReviewItem` |
| **Validator** (Structural) | êµ¬ì¡°ì  ìœ„í—˜(ë¶€ì •/ëŒ€ì¡°/ë°˜ì–´) ê²€ì¦. Risk scope(ì¸ë±ìŠ¤ ë²”ìœ„), ì¼ê´€ì„± ì ìˆ˜, **Correction Proposal**(FLIP_POLARITY ë“±). | `agents/prompts/validator_stage1.md`, `validator_stage2.md` | `StructuralValidatorStage1Schema` (structural_risks, consistency_score, correction_proposals) |
| **Moderator** | **ê·œì¹™ ê¸°ë°˜**(LLM ë¯¸ì‚¬ìš©). Stage1/Stage2/Validator ê²°ê³¼ë¥¼ Rule A~D, M, Eë¡œ ì¢…í•©í•´ ìµœì¢… ë¼ë²¨Â·confidenceÂ·rationale ê²°ì •. | `agents/prompts/moderator.md` | Rule A: Stage2 ì‹ ë¢°ë„ ê¸‰ë½ ì‹œ Stage1 ìœ ì§€ / Rule B: Validator ì œì•ˆ ìš°ì„  ê³ ë ¤ / Rule C: ìœ„í—˜Â·ì œì•ˆ ì‹œ Validator veto / Rule D: ì‹ ë¢°ë„ íƒ€ì´ë¸Œë ˆì´í¬ / Rule M: Stage1â†”Stage2 ì¶©ëŒ ì‹œ mixed / Rule E: Debate í•©ì˜ íŒíŠ¸ ë°˜ì˜ |

### Debate ë ˆì´ì–´ (ì„ íƒ, `enable_debate: true` ì‹œ) â€” ì—¬ê¸°ì„œë§Œ í˜ë¥´ì†Œë‚˜ ë¶€ì—¬

í† ë¡  ë‹¨ê³„ì—ì„œ **ë°œì–¸ì 3ëª…**ì—ê²Œë§Œ `DebatePersona`ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤. `DebateOrchestrator`ê°€ `self.personas`(analyst/empath/critic)ë¥¼ ì½ì–´, ê° ë°œì–¸ ì‹œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— `[PERSONA]\n{persona.model_dump_json()}` í˜•íƒœë¡œ ì£¼ì…í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸: `agents/prompts/debate_speaker.md`, `debate_judge.md`. ìŠ¤í‚¤ë§ˆ: `DebatePersona`, `DebateTurn`, `DebateSummary` (schemas). ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ: config `debate.personas`, `debate.order`.

| í˜ë¥´ì†Œë‚˜ (ë°œì–¸ì) | stance | ì—­í• Â·ìŠ¤íƒ€ì¼ | ëª©í‘œ |
|------------------|--------|-------------|------|
| **ë¶„ì„ê°€ íŒ¨ë„** | neutral | ê±´ì¡°í•˜ê³  ê·¼ê±° ì¤‘ì‹¬ | ì¦ê±° ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë¦½ì  íŒë‹¨ ì œì‹œ |
| **ê³µê°ê°€ íŒ¨ë„** | pro | ë”°ëœ»í•˜ê³  ê°ì„±ì  | ê¸ì •/ì§€ì§€ì  ë§¥ë½ ê°•í™” |
| **ë¹„í‰ê°€ íŒ¨ë„** | con | ë‚ ì¹´ë¡­ê³  ë…¼ë¦¬ì  | ë¶€ì •/ë¹„íŒì  ë§¥ë½ ê°•í™” |

ë°œì–¸ì€ Planning â†’ Reflection â†’ Action ìˆœìœ¼ë¡œ ìƒì„±ë˜ë©°, ì‹¬íŒ(Judge)ì´ winner/consensus/key_agreementsÂ·key_disagreements/rationaleì„ ìš”ì•½í•©ë‹ˆë‹¤. ì´ ìš”ì•½ì€ Stage2 ë¦¬ë·° ì»¨í…ìŠ¤íŠ¸ì™€ Moderator Rule Eì— ì‚¬ìš©ë©ë‹ˆë‹¤.

## ğŸ“ˆ ê´€ì°°/ì§€í‘œ
ë¦¬í¬íŠ¸ ë° ì§€í‘œëŠ” `scripts/scorecard_from_smoke.py`, `scripts/structural_error_aggregator.py`, `scripts/build_metric_report.py`ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

## ğŸ†˜ ìì£¼ ê²ªëŠ” ë¬¸ì œ

1) **ì‹¤í–‰ì´ ë„ˆë¬´ ë¹ ë¥´ê²Œ ëë‚˜ìš”**
- mock ëª¨ë¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ì„ ì“°ë ¤ë©´ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.

2) **ì—ëŸ¬: leakage_guard**
- `test_small.csv`ì²˜ëŸ¼ ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë§‰í™ë‹ˆë‹¤.  
  `experiments/configs/test_small.yaml`ì„ ì‚¬ìš©í•˜ì„¸ìš”.

3) **HTML ë¦¬í¬íŠ¸ê°€ ì•ˆ ì—´ë ¤ìš”**
- ë¸Œë¼ìš°ì €ì—ì„œ `reports/.../metric_report.html`ì„ ì§ì ‘ ì—´ì–´ë³´ì„¸ìš”.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
kr-sentimental-agent/
â”œâ”€â”€ agents/                          # ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ supervisor_agent.py         # í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚   â”œâ”€â”€ prompts/                    # ATE/ATSA/Validator/Debate/Moderator í”„ë¡¬í”„íŠ¸
â”‚   â””â”€â”€ specialized_agents/         # ATE, ATSA, Validator, Moderator
â”œâ”€â”€ tools/                           # LLMÂ·ë°ì´í„°Â·ë°ëª¨
â”‚   â”œâ”€â”€ backbone_client.py          # LLM ë°±ë³¸
â”‚   â”œâ”€â”€ llm_runner.py                # êµ¬ì¡°í™” ì¶œë ¥Â·ì¬ì‹œë„
â”‚   â”œâ”€â”€ data_tools/                  # CSV/JSONL ë¡œë”, ë¼ë²¨ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ demo_sampler.py              # ë°ëª¨ ìƒ˜í”Œë§
â”œâ”€â”€ data/                            # ë°ì´í„° ë¡œë”
â”‚   â””â”€â”€ datasets/                    # load_datasets, ê²½ë¡œ í•´ì„
â”œâ”€â”€ memory/                          # ì—í”¼ì†Œë”• ë©”ëª¨ë¦¬ (C1/C2/C3)
â”‚   â”œâ”€â”€ episodic_orchestrator.py    # ê²€ìƒ‰Â·ì£¼ì…
â”‚   â”œâ”€â”€ retriever.py                 # ì‹œê·¸ë‹ˆì²˜Â·ìœ ì‚¬ë„
â”‚   â””â”€â”€ advisory_builder.py         # ì–´ë“œë°”ì´ì € í…ìŠ¤íŠ¸
â”œâ”€â”€ metrics/                         # Tuple í‰ê°€
â”‚   â””â”€â”€ eval_tuple.py                # gold_tuples, tuples_to_pairs, F1
â”œâ”€â”€ schemas/                         # ì—ì´ì „íŠ¸ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ agent_outputs.py            # AspectExtraction, Sentiment, Validator
â”œâ”€â”€ evaluation/                      # ë² ì´ìŠ¤ë¼ì¸Â·í‰ê°€
â”‚   â””â”€â”€ baselines.py                 # make_runner, resolve_run_mode
â”œâ”€â”€ experiments/                     # ì‹¤í—˜ ì„¤ì •Â·ì‹¤í–‰
â”‚   â”œâ”€â”€ configs/                     # YAML ì„¤ì • (mini, real, real_n100_seed1_c1/c2/c3, abl_*)
â”‚   â”‚   â””â”€â”€ datasets/                # mini, mini2, mini3, real_n100_seed1, valid/ í´ë“œ ë“±
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ run_experiments.py       # ì‹¤í—˜ ë£¨í”„, scorecards(ì›ë³¸), gold ì£¼ì…
â”œâ”€â”€ scripts/                         # íŒŒì´í”„ë¼ì¸Â·ë©”íŠ¸ë¦­Â·ì§„ë‹¨
â”‚   â”œâ”€â”€ run_pipeline.py             # í†µí•© CLI (ì‹¤í—˜ â†’ ìŠ¤ëƒ…ìƒ· â†’ ë¦¬í¬íŠ¸ â†’ ë©”íŠ¸ë¦­)
â”‚   â”œâ”€â”€ scorecard_from_smoke.py       # outputs â†’ scorecards (--out í•„ìˆ˜ë¡œ ì›ë³¸ ë®ì–´ì“°ê¸° ë°©ì§€)
â”‚   â”œâ”€â”€ structural_error_aggregator.py  # structural_metrics, triptych, inconsistency_flags
â”‚   â”œâ”€â”€ build_metric_report.py       # metric_report.html
â”‚   â”œâ”€â”€ aggregate_seed_metrics.py    # ì‹œë“œ ë¨¸ì§•, í‰ê· Â±í‘œì¤€í¸ì°¨
â”‚   â”œâ”€â”€ consistency_checklist.py    # GO/NO-GO ì •í•©ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸
â”‚   â””â”€â”€ run_real_n100_c1_c2_c3.ps1   # real n100 C1â†’C2â†’C3 ìˆœì°¨ + ë¨¸ì§€
â”œâ”€â”€ analysis/                        # ë©”ëª¨ë¦¬ ì„±ì¥Â·í”Œë¡¯
â”œâ”€â”€ docs/                            # ì‹¤í–‰Â·í‰ê°€Â·ì •ì±… ë¬¸ì„œ
â”œâ”€â”€ results/                         # ëŸ°ë³„ ì‚°ì¶œë¬¼ (run_idë³„ ë””ë ‰í„°ë¦¬)
â”‚   â””â”€â”€ <run_id>_<mode>/
â”‚       â”œâ”€â”€ manifest.json, outputs.jsonl, scorecards.jsonl, traces.jsonl
â”‚       â”œâ”€â”€ derived/                 # metrics, diagnostics, tables, scorecards(smoke ì¬ìƒì„±)
â”‚       â”œâ”€â”€ paper_outputs/
â”‚       â””â”€â”€ ops_outputs/
â””â”€â”€ reports/                         # HTML ë¦¬í¬íŠ¸ (run_idë³„)
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì—°ë½ì²˜

- í”„ë¡œì íŠ¸ ë§í¬: [https://github.com/cloudnative-app/kr-sentimental-agent](https://github.com/cloudnative-app/kr-sentimental-agent)
- ì´ìŠˆ ë¦¬í¬íŠ¸: [https://github.com/cloudnative-app/kr-sentimental-agent/issues](https://github.com/cloudnative-app/kr-sentimental-agent/issues)

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- **ì‹¤í–‰Â·ì„¤ì •**: `docs/how_to_run.md` (run_pipeline, ì‹œë“œ ë°˜ë³µ, ë¨¸ì§•Â·ê²½ë¡œ, real n100 C1/C2/C3)
- **Tuple í‰ê°€**: `docs/absa_tuple_eval.md` (gold_tuples, tuple_f1)
- **Scorecard ê²½ë¡œÂ·ì •í•©ì„±**: `docs/scorecard_path_and_consistency_checklist.md` (ë®ì–´ì“°ê¸° ê¸ˆì§€, meta.source, consistency_checklist)
- **ì‹¤ì œ ëŸ° ëª…ë ¹ì–´ (real n100)**: `docs/run_real_n100_c1_c2_c3_commands.md`
- **mini2/mini3**: `docs/experiment_mini2_two_seeds_two_runs.md`, `experiments/configs/experiment_mini3.yaml`
- **origin vs ë¡œì»¬ ì°¨ì´**: `docs/github_vs_local_diff.md`

## Provider dry-run (real backbone quick check)

```bash
python scripts/provider_dry_run.py --text "ì„œë¹„ìŠ¤ëŠ” ì¹œì ˆí–ˆì§€ë§Œ ìŒì‹ì€ ë³„ë¡œì˜€ì–´" --mode proposed
```

Required env vars (names only):
- OpenAI: OPENAI_API_KEY (OPENAI_BASE_URL optional)
- Anthropic: ANTHROPIC_API_KEY (ANTHROPIC_BASE_URL optional)
- Google Gemini: GOOGLE_API_KEY, GENAI_API_KEY
