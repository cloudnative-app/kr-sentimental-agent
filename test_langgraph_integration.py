#!/usr/bin/env python3
"""
LangGraph í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
sys.path.append(os.path.dirname(__file__))

from agents.supervisor_agent import SupervisorAgent
from agents.two_stage_supervisor import TwoStageSupervisorAgent


def test_llm_specialized_agents():
    """Test LLM-based specialized agents."""
    print("ğŸ§ª Testing LLM-based specialized agents...")
    
    try:
        # Create LLM-based agents
        from agents.specialized_agents import AnalystAgent, EmpathAgent, CriticAgent
        
        analyst = AnalystAgent("openai", "openai", "gpt-3.5-turbo")
        empath = EmpathAgent("openai", "openai", "gpt-3.5-turbo")
        critic = CriticAgent("openai", "openai", "gpt-3.5-turbo")
        
        test_text = "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ìƒì¾Œí•´!"
        
        # Test individual agents
        analyst_result = analyst.run(test_text)
        empath_result = empath.run(test_text)
        critic_result = critic.run(test_text)
        
        print(f"âœ… LLM Analyst: {analyst_result.label} ({analyst_result.score:.3f})")
        print(f"âœ… LLM Empath: {empath_result.label} ({empath_result.score:.3f})")
        print(f"âœ… LLM Critic: {critic_result.label} ({critic_result.score:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLM specialized agents test failed: {e}")
        return False


def test_langchain_agents():
    """Test LangChain-based individual agents."""
    print("\nğŸ§ª Testing LangChain-based individual agents...")
    
    try:
        # Create agents
        analyst = LangChainAnalystAgent("openai", "gpt-3.5-turbo")
        empath = LangChainEmpathAgent("openai", "gpt-3.5-turbo")
        critic = LangChainCriticAgent("openai", "gpt-3.5-turbo")
        
        test_text = "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ìƒì¾Œí•´!"
        
        # Test individual agents
        analyst_result = analyst.run(test_text)
        empath_result = empath.run(test_text)
        critic_result = critic.run(test_text)
        
        print(f"âœ… LangChain Analyst: {analyst_result.label} ({analyst_result.score:.3f})")
        print(f"âœ… LangChain Empath: {empath_result.label} ({empath_result.score:.3f})")
        print(f"âœ… LangChain Critic: {critic_result.label} ({critic_result.score:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ LangChain agents test failed: {e}")
        return False


def test_langgraph_supervisor():
    """Test LangGraph-based supervisor."""
    print("\nğŸ§ª Testing LangGraph-based supervisor...")
    
    try:
        # Create LangGraph supervisor
        supervisor = LangGraphSupervisorAgent("openai", "gpt-3.5-turbo")
        
        test_text = "ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë¯¸ì—†ì—ˆì–´. ì‹œê°„ ë‚­ë¹„ì˜€ì–´."
        
        # Test supervisor
        results = supervisor.run(test_text)
        
        print(f"âœ… Analyst: {results['analyst'].label} ({results['analyst'].score:.3f})")
        print(f"âœ… Empath: {results['empath'].label} ({results['empath'].score:.3f})")
        print(f"âœ… Critic: {results['critic'].label} ({results['critic'].score:.3f})")
        print(f"âœ… Final: {results['final'].label} ({results['final'].score:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ LangGraph supervisor test failed: {e}")
        return False


def test_two_stage_supervisor():
    """Test two-stage supervisor (matches image structure)."""
    print("\nğŸ§ª Testing two-stage supervisor...")
    
    try:
        # Create two-stage supervisor
        supervisor = TwoStageSupervisorAgent("openai", "gpt-3.5-turbo")
        
        test_text = "ì°¸ ì˜í•˜ëŠ” ì§“ì´ë‹¤... ì •ë§ ëŒ€ë‹¨í•´!"
        
        # Test two-stage workflow
        results = supervisor.run(test_text)
        
        print(f"âœ… Independent Analyst: {results['independent_analyst'].label} ({results['independent_analyst'].score:.3f})")
        print(f"âœ… Independent Empath: {results['independent_empath'].label} ({results['independent_empath'].score:.3f})")
        print(f"âœ… Independent Critic: {results['independent_critic'].label} ({results['independent_critic'].score:.3f})")
        print(f"âœ… Deliberation Analyst: {results['deliberation_analyst'].label} ({results['deliberation_analyst'].score:.3f})")
        print(f"âœ… Deliberation Empath: {results['deliberation_empath'].label} ({results['deliberation_empath'].score:.3f})")
        print(f"âœ… Deliberation Critic: {results['deliberation_critic'].label} ({results['deliberation_critic'].score:.3f})")
        print(f"âœ… Final: {results['final'].label} ({results['final'].score:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ Two-stage supervisor test failed: {e}")
        return False


def test_unified_supervisor():
    """Test unified supervisor with different modes."""
    print("\nğŸ§ª Testing unified supervisor...")
    
    try:
        test_text = "ì°¸ ì˜í•˜ëŠ” ì§“ì´ë‹¤... ì •ë§ ëŒ€ë‹¨í•´!"
        
        # Test Two-Stage mode (matches image)
        print("Testing Two-Stage mode...")
        supervisor_ts = SupervisorAgent(llm_provider="openai", model_name="gpt-3.5-turbo")
        results_ts = supervisor_ts.run(test_text)
        print(f"âœ… Two-Stage Final: {results_ts['final'].label} ({results_ts['final'].score:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ Unified supervisor test failed: {e}")
        return False


def main():
    """Run all tests."""
    print("ğŸš€ Starting LangGraph/LangChain integration tests...\n")
    
    # Check environment variables
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  Warning: OPENAI_API_KEY not set. Some tests may fail.")
    
    tests = [
        test_llm_specialized_agents,
        test_langchain_agents,
        test_langgraph_supervisor,
        test_two_stage_supervisor,
        test_unified_supervisor
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
    
    print(f"\nğŸ“Š Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All tests passed! LangGraph/LangChain integration is working correctly.")
        return 0
    else:
        print("âŒ Some tests failed. Please check the error messages above.")
        return 1


if __name__ == "__main__":
    exit(main())
